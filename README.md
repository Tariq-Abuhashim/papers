## List of key papers:
### DETR:
- End-to-End Object Detection with Transformers. [paper](https://arxiv.org/abs/2005.12872)  
- Deformable Convolutional Networks. [paper](https://arxiv.org/abs/1703.06211)  
- Deformable DETR: Deformable Transformers for End-to-End Object Detection. [paper](https://arxiv.org/abs/2010.04159)  
- DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR. [paper](https://arxiv.org/abs/2201.12329)  
- DN-DETR: Accelerate DETR Training by Introducing Query DeNoising. [paper](https://arxiv.org/abs/2203.01305)  
- DINO: DETR with Improved DeNoising AnchorBoxes for End-to-End Object Detection. [paper](https://arxiv.org/abs/2203.03605)  
- DETRs Beat YOLOs on Real-time Object Detection. [paper](https://arxiv.org/abs/2304.08069)  
- RT-DETRv3: Real-time End-to-End Object Detection with Hierarchical Dense Positive Supervision. [paper](https://arxiv.org/abs/2409.08475)

### Language
Attention Is All You Need. [paper](https://arxiv.org/abs/1706.03762)  
Transformer Self-Attention Mechanism Visualized. [video](https://www.youtube.com/watch?v=u8pSGp__0Xk)  
Neural Networks: Zero to Hero. [website](https://karpathy.ai/zero-to-hero.html)  
Language Models are Few-Shot Learners. [paper](https://arxiv.org/abs/2005.14165)  
OpenAI Agents SDK. [code](https://github.com/openai/openai-agents-python?tab=readme-ov-file)  
MetaGPT: The Multi-Agent Framework. [code](https://github.com/geekan/MetaGPT)  
DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models. [paper](https://arxiv.org/abs/2401.06066)  
Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts. [paper](https://arxiv.org/abs/2408.15664)  
DeepSeek-V3 Technical Report. [paper](https://arxiv.org/abs/2412.19437)  
DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. [paper](https://arxiv.org/abs/2501.12948)  

### Multimodal
[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)  
[PaLM-E: An Embodied Multimodal Language Model](https://arxiv.org/abs/2303.03378)  
[M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place](https://arxiv.org/abs/2311.00926)  
[]()

### Visual SLAM
[ORB-SLAM2: an Open-Source SLAM System for Monocular, Stereo and RGB-D Cameras](https://arxiv.org/abs/1610.06475)  
[ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM](https://arxiv.org/abs/2007.11898)  
[Probabilistic Semi-Dense Mapping from Highly Accurate Feature-Based Monocular SLAM](https://www.roboticsproceedings.org/rss11/p41.pdf)  
[DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras](https://arxiv.org/abs/2108.10869)  
[Deep Patch Visual Odometry](https://arxiv.org/abs/2208.04726)  
[Deep Patch Visual SLAM](https://arxiv.org/abs/2408.01654)  
[MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors](https://arxiv.org/abs/2412.12392)  
[]()

### Collaborative SLAM
[COVINS: Visual-Inertial SLAM for Centralized Collaboration](https://arxiv.org/abs/2108.05756)  
[SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation](https://arxiv.org/abs/2406.17249)  
[]()  

### Point-Clouds
[Difference of Normals as a Multi-Scale Operator in Unorganized Point Clouds](https://arxiv.org/abs/1209.1759)  
[Fast Range Image-Based Segmentation of Sparse 3D Laser Scans for Online Operation](https://www.ipb.uni-bonn.de/pdfs/bogoslavskyi16iros.pdf)  
[PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593)  
[PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space](https://arxiv.org/abs/1706.02413)  
[VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection](https://arxiv.org/abs/1711.06396)  
[PointPillars: Fast Encoders for Object Detection from Point Clouds](https://arxiv.org/abs/1812.05784)  
[SEGCloud: Semantic Segmentation of 3D Point Clouds](https://arxiv.org/abs/1710.07563)  
[Supplementary Material for SEGCloud: Semantic Segmentation of 3D Point Clouds](https://cvgl.stanford.edu/projects/segcloud/supplementary.pdf)  
[]()

### Structure from Motion
[Global Structure-from-Motion Revisited](https://arxiv.org/abs/2407.20219)  
[Supplementary Material for “3D Line Mapping Revisited”](http://b1ueber2y.me/projects/LIMAP/limap-supp.pdf)  
[3D Line Mapping Revisited](https://arxiv.org/abs/2303.17504)  

### LiDAR SLAM 
[Faster-LIO: Lightweight Tightly Coupled Lidar-Inertial Odometry Using Parallel Sparse Incremental Voxels](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9718203)  
[]()

### Kumar Lab
[TreeScope: An Agricultural Robotics Dataset for LiDAR-Based Mapping of Trees in Forests and Orchards](https://arxiv.org/abs/2310.02162)  
[]()  

### Applications
Automatic number plate recognition with Python, Yolov8 and EasyOCR. [video](https://www.youtube.com/watch?v=fyJB1t0o0ms), [code](https://github.com/computervisioneng/automatic-number-plate-recognition-python-yolov8)  

### Website creation
The source [code](https://github.com/nerfies/nerfies.github.io) for the [Nerfies website](https://nerfies.github.io/).
