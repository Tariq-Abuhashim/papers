## List of key papers:
### DETR:
[End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)  
[DINO: DETR with Improved DeNoising AnchorBoxes for End-to-End Object Detection](https://arxiv.org/abs/2203.03605)  
[DETRs Beat YOLOs on Real-time Object Detection](https://arxiv.org/abs/2304.08069)  
[RT-DETRv3: Real-time End-to-End Object Detection with Hierarchical Dense Positive Supervision](https://arxiv.org/abs/2409.08475)

### Language Modelling
[Attention Is All You Need](https://arxiv.org/abs/1706.03762)  
[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)  
[]()  

### Multimodal Modelling
[PaLM-E: An Embodied Multimodal Language Model](https://arxiv.org/abs/2303.03378)  
[M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place](https://arxiv.org/abs/2311.00926)  
[]()


### Visual SLAM
[ORB-SLAM2: an Open-Source SLAM System for Monocular, Stereo and RGB-D Cameras](https://arxiv.org/abs/1610.06475)  
[ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM](https://arxiv.org/abs/2007.11898)  
[Probabilistic Semi-Dense Mapping from Highly Accurate Feature-Based Monocular SLAM](https://www.roboticsproceedings.org/rss11/p41.pdf)  
[DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras](https://arxiv.org/abs/2108.10869)  
[Deep Patch Visual Odometry](https://arxiv.org/abs/2208.04726)  
[Deep Patch Visual SLAM](https://arxiv.org/abs/2408.01654)  
[]()

### Collaborative SLAM
[COVINS: Visual-Inertial SLAM for Centralized Collaboration](https://arxiv.org/abs/2108.05756)  
[SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation](https://arxiv.org/abs/2406.17249)  
[]()  

### Point-Clouds
[Difference of Normals as a Multi-Scale Operator in Unorganized Point Clouds](https://arxiv.org/abs/1209.1759)  
[Fast Range Image-Based Segmentation of Sparse 3D Laser Scans for Online Operation](https://www.ipb.uni-bonn.de/pdfs/bogoslavskyi16iros.pdf)  
[PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation](https://arxiv.org/abs/1612.00593)  
[PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space](https://arxiv.org/abs/1706.02413)  
[VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection](https://arxiv.org/abs/1711.06396)  
[PointPillars: Fast Encoders for Object Detection from Point Clouds](https://arxiv.org/abs/1812.05784)  
[SEGCloud: Semantic Segmentation of 3D Point Clouds](https://arxiv.org/abs/1710.07563)  
[Supplementary Material for SEGCloud: Semantic Segmentation of 3D Point Clouds](https://cvgl.stanford.edu/projects/segcloud/supplementary.pdf)  
[]()

### Structure from Motion
[Global Structure-from-Motion Revisited](https://arxiv.org/abs/2407.20219)  
[Supplementary Material for “3D Line Mapping Revisited”](http://b1ueber2y.me/projects/LIMAP/limap-supp.pdf)  
[3D Line Mapping Revisited](https://arxiv.org/abs/2303.17504)  


### LiDAR SLAM 
[Faster-LIO: Lightweight Tightly Coupled Lidar-Inertial Odometry Using Parallel Sparse Incremental Voxels](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9718203)  
[]()

### Kumar Lab
[TreeScope: An Agricultural Robotics Dataset for LiDAR-Based Mapping of Trees in Forests and Orchards](https://arxiv.org/abs/2310.02162)  
[]()  

